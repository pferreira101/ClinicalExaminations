{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP - Computação Natural\n",
    "#### \"Predict whether a mammogram mass is benign or malignant\"\n",
    "\n",
    "1. BI-RADS assessment: 1 to 5 (ordinal)  \n",
    "2. Age: patient's age in years (integer)\n",
    "3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\n",
    "4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\n",
    "5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\n",
    "6. Severity: benign=0 or malignant=1 (binominal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy import stats\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mammographic_masses.data.txt', names=['BI_RADS','Age','Shape','Margin','Density','Severity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert missing data (indicated by a ?) into NaN and add the appropriate column names (BI_RADS, age, shape, margin, density, and severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace('?',np.nan)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop BI_RADS column because it has no influence on the severity forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['BI_RADS', 'Density'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert datatype 'object' to 'float64'**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data.index = np.arange(1, len(data) + 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect outliers using mathematical function Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.abs(stats.zscore(data))\n",
    "threshold = 2\n",
    "print(np.where(z > threshold))\n",
    "# The first array contains the list of row numbers and second array respective column numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect outliers using IQR Score\n",
    "Similar to Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "iqr = Q3 - Q1\n",
    "print(iqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers using Z-Score\n",
    "\n",
    "##### + explanations: https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como z-score estava\n",
    "data = data[(np.abs(stats.zscore(data)) < 2).all(axis=1)]\n",
    "data.index = np.arange(1, len(data) + 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discretize Age feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = data.loc[:,'Age']\n",
    "data['Age'] = pd.cut(x=age, bins=[0,40, 55,60, 100], labels=[\"<40\",\"40-55\",\"55-60\",\">60\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_palette = ['tab:green','tab:red']\n",
    "\n",
    "def categorical_summarized(dataframe, x=None, y=None, hue=None, palette='Set1', verbose=True):\n",
    "    if x == None:\n",
    "        column_interested = y\n",
    "    else:\n",
    "        column_interested = x\n",
    "    series = dataframe[column_interested]\n",
    "    print(series.describe())\n",
    "    print('mode: ', series.mode())\n",
    "    if verbose:\n",
    "        print('='*80)\n",
    "        print(series.value_counts())\n",
    "\n",
    "    sns.countplot(x=x, y=y, hue=hue, data=dataframe, palette=palette)\n",
    "    plt.show()\n",
    "    \n",
    "categorical_summarized(data, x = 'Age', hue='Severity', palette=c_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One Hot Encode all features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(data['Age'])\n",
    "data = data.drop('Age',axis = 1)\n",
    "data = data.join(one_hot)\n",
    "data = data.rename(columns={1.0: \"Age_1\", 2.0: \"Age_2\", 3.0: \"Age_3\", 4.0: \"Age_4\"})\n",
    "\n",
    "one_hot = pd.get_dummies(data['Shape'])\n",
    "data = data.drop('Shape',axis = 1)\n",
    "data = data.join(one_hot)\n",
    "data = data.rename(columns={1.0: \"Shape_1\", 2.0: \"Shape_2\", 3.0: \"Shape_3\", 4.0: \"Shape_4\"})\n",
    "\n",
    "one_hot = pd.get_dummies(data['Margin'])\n",
    "data = data.drop('Margin',axis = 1)\n",
    "data = data.join(one_hot)\n",
    "data = data.rename(columns={1.0: \"Margin_1\", 2.0: \"Margin_2\", 3.0: \"Margin_3\", 4.0: \"Margin_4\", 5.0: \"Margin_5\"})\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create training and testing sets of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data.drop('Severity',axis=1).to_numpy()\n",
    "y = data['Severity'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.info(X_train)\n",
    "print(\"---\")\n",
    "np.info(X_test)\n",
    "print(\"---\")\n",
    "np.info(y_train)\n",
    "print(\"---\")\n",
    "np.info(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks & Genetic Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que contrói o modelo ANN\n",
    "def buildModel(hidden_layers, nodes_per_layer, activation_fn, optimizer, lr, loss_fn, metrics, inputs=13):\n",
    "    model = Sequential()\n",
    "    #add input layer\n",
    "    model.add(Dense(inputs, activation=\"sigmoid\", input_shape=(inputs,)))\n",
    "\n",
    "    #add hidden layers    \n",
    "    for i in range(int(hidden_layers)):\n",
    "        model.add(Dense(int(nodes_per_layer), activation=activation_fn))\n",
    "\n",
    "    #add output layer\n",
    "    model.add(Dense(1,activation=\"sigmoid\"))\n",
    "    \n",
    "    if(optimizer=='SGD'): optimizer = SGD(learning_rate=lr)\n",
    "    elif(optimizer=='RMSprop'): optimizer = RMSprop(learning_rate=lr)\n",
    "    elif(optimizer=='Adam'): optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "    #compile model\n",
    "    model.compile(optimizer, loss=loss_fn, metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Função que realiza uma previsão para o modelo\n",
    "def evaluatePredictions(model, input_attributes, labels):\n",
    "    predicted = model.predict(input_attributes)\n",
    "    \n",
    "\n",
    "    LP = roundPredictions(predicted)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, LP)\n",
    "    recall = recall_score(labels, LP, average=None)\n",
    "    precision = precision_score(labels, LP, average=None)\n",
    "    \n",
    "    return accuracy, recall[0], precision[0], recall[1], precision[1]\n",
    "\n",
    "    \n",
    "#Função que cria a população inicial\n",
    "#parameters=[hidden_layers,nodes_per_layer,activation_fn,learning_rate,optimizer,loss_fn]\n",
    "def create_new_population():\n",
    "    \n",
    "    population=[]\n",
    "    \n",
    "    for i in range(10):\n",
    "        cromo=[]\n",
    "        cromo.append(np.random.randint(low=1, high=17))\n",
    "        cromo.append(np.random.choice([1, 2, 4, 8, 16, 32, 64, 128, 256]))\n",
    "        cromo.append(np.random.randint(low=0, high=6))\n",
    "        cromo.append(np.random.choice([0.001, 0.01, 0.1, 1]))\n",
    "        cromo.append(np.random.randint(low=0, high=3))\n",
    "        cromo.append(np.random.randint(low=0, high=3))\n",
    "        population.append(cromo)\n",
    "        \n",
    "    return np.array(population)\n",
    "\n",
    "#Função genérica que atualiza os argumentos do classifier\n",
    "#parameters=[hidden_layers,nodes_per_layer,activation_fn,learning_rate,optimizer,loss_fn]\n",
    "def update_model_parameters(parameters):\n",
    "    \n",
    "    if((parameters[2]) == 0): a_f = 'relu'\n",
    "    if((parameters[2]) == 1): a_f = 'selu'\n",
    "    if((parameters[2]) == 2): a_f = 'sigmoid'\n",
    "    if((parameters[2]) == 3): a_f = 'tanh'\n",
    "    if((parameters[2]) == 4): a_f = 'linear'\n",
    "    if((parameters[2]) == 5): a_f = 'softmax'\n",
    "        \n",
    "        \n",
    "    if((parameters[4]) == 0): opt_f = 'SGD'\n",
    "    if((parameters[4]) == 1): opt_f = 'RMSprop'\n",
    "    if((parameters[4]) == 2): opt_f = 'Adam'\n",
    "        \n",
    "    if((parameters[5]) == 0): loss = 'binary_crossentropy'\n",
    "    if((parameters[5]) == 1): loss = 'hinge'\n",
    "    if((parameters[5]) == 2): loss = 'squared_hinge'\n",
    "        \n",
    "    model = buildModel(parameters[0], parameters[1], a_f, opt_f, parameters[3], loss, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def select_mating_pool(pop, fitness, parents_fitness, num_parents):\n",
    "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "    parents = np.empty((num_parents, pop.shape[1]))\n",
    "    parents_fitness = []\n",
    "    for parent_num in range(num_parents):\n",
    "        #save fitness values of best parents\n",
    "        parents_fitness.append(np.max(fitness))\n",
    "        #save best parents\n",
    "        max_fitness_idx = np.where(fitness == np.max(fitness))\n",
    "        max_fitness_idx = max_fitness_idx[0][0]\n",
    "        parents[parent_num, :] = pop[max_fitness_idx, :]\n",
    "        fitness[max_fitness_idx] = -99999999999\n",
    "        \n",
    "    return parents, parents_fitness\n",
    "\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = np.empty(offspring_size)\n",
    "    # The point at which crossover takes place between two parents. Usually it is at the center.\n",
    "    crossover_point = np.uint8(offspring_size[1]/2)\n",
    "\n",
    "    for k in range(offspring_size[0]):\n",
    "        # Index of the first parent to mate.\n",
    "        parent1_idx = k%parents.shape[0]\n",
    "        # Index of the second parent to mate.\n",
    "        parent2_idx = (k+1)%parents.shape[0]\n",
    "        # The new offspring will have its first half of its genes taken from the first parent.\n",
    "        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]\n",
    "        # The new offspring will have its second half of its genes taken from the second parent.\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "    return offspring\n",
    "\n",
    "def mutation(offspring_crossover):\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        \n",
    "        # Select which gene to mutate\n",
    "        select_gene = np.random.randint(low=0, high=6)\n",
    " \n",
    "        if(select_gene == 0):\n",
    "            #num_hidden_layers mutation\n",
    "            random_value = np.random.randint(low=1, high=17)\n",
    "            offspring_crossover[idx,0] = random_value\n",
    "        if(select_gene == 1):\n",
    "            #num_nodes_per_layer mutation\n",
    "            random_value = np.random.choice([4, 8, 16, 32, 64, 128, 256])\n",
    "            offspring_crossover[idx,1] = random_value\n",
    "        if(select_gene == 2):\n",
    "            #activation function mutation\n",
    "            random_value = np.random.randint(low=0, high=6)\n",
    "            offspring_crossover[idx,2] = random_value\n",
    "        if(select_gene == 3):\n",
    "            #learning rate mutation\n",
    "            random_value = np.random.choice([0.001, 0.01, 0.1, 1])\n",
    "            offspring_crossover[idx,3] = random_value\n",
    "        if(select_gene == 4):\n",
    "            #optimizer mutation\n",
    "            random_value = np.random.randint(low=0, high=3)\n",
    "            offspring_crossover[idx,4] = random_value\n",
    "        if(select_gene == 5):\n",
    "            #loss function mutation\n",
    "            random_value = np.random.randint(low=0, high=3)\n",
    "            offspring_crossover[idx,5] = random_value\n",
    "            \n",
    "    return offspring_crossover\n",
    "\n",
    "def printChromo(chromo, tab=False):\n",
    "    \n",
    "    identation = \"\\t\" if tab else \"\"\n",
    "    \n",
    "    if((chromo[2]) == 0): a_f = 'relu'\n",
    "    if((chromo[2]) == 1): a_f = 'selu'\n",
    "    if((chromo[2]) == 2): a_f = 'sigmoid'\n",
    "    if((chromo[2]) == 3): a_f = 'tanh'\n",
    "    if((chromo[2]) == 4): a_f = 'linear'\n",
    "    if((chromo[2]) == 5): a_f = 'softmax'\n",
    "        \n",
    "        \n",
    "    if((chromo[4]) == 0): opt_f = 'SGD'\n",
    "    if((chromo[4]) == 1): opt_f = 'RMSprop'\n",
    "    if((chromo[4]) == 2): opt_f = 'Adam'\n",
    "        \n",
    "    if((chromo[5]) == 0): loss = 'binary_crossentropy'\n",
    "    if((chromo[5]) == 1): loss = 'hinge'\n",
    "    if((chromo[5]) == 2): loss = 'squared_hinge'\n",
    "        \n",
    "    print(identation + \"Layers: {} |\".format(int(chromo[0])),\"Nodes: {} |\".format(int(chromo[1])),\"Act_F: {} |\".format(a_f),\"Opti: {} |\".format(opt_f), \"LR: {} |\".format(chromo[3]),\"Loss: {}\".format(loss))\n",
    "    \n",
    "def printChromos(chromos, tab=False):\n",
    "    for chromo in chromos:\n",
    "        printChromo(chromo, tab)\n",
    "    \n",
    "def roundPredictions(predicted):\n",
    "    # arredondar para 0 ou 1 pois pretende-se um output binário\n",
    "    LP = []\n",
    "    f = lambda x: int(round(x))\n",
    "    vfunc = np.vectorize(f)\n",
    "    \n",
    "    for prev in predicted:\n",
    "        prev = vfunc(prev)\n",
    "        LP.append(prev)\n",
    "    \n",
    "    return LP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Fold Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_folds = 10\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keras ANN built from specific parameters (one specific chromosome)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateChromosome(chromosome):\n",
    "    scores=[]\n",
    "    recalls_0=[]\n",
    "    precisions_0=[]\n",
    "    recalls_1=[]\n",
    "    precisions_1=[]\n",
    "    \n",
    "    model = update_model_parameters(chromosome)\n",
    "    \n",
    "    fold_no=1\n",
    "    \n",
    "    for train, test in kfold.split(X_train, y_train):\n",
    "\n",
    "        history = model.fit(X_train[train], y_train[train],\n",
    "              epochs=30,\n",
    "              batch_size=64,\n",
    "              verbose=0)\n",
    "\n",
    "        score = model.evaluate(X_train[test], y_train[test], batch_size=64, verbose=0)      \n",
    "        accuracy, recall_0, precision_0, recall_1, precision_1 = evaluatePredictions(model, X_train[test], y_train[test])\n",
    "\n",
    "        #Adding all metrics to arrays\n",
    "        scores.append(score[1])\n",
    "        recalls_0.append(recall_0)\n",
    "        precisions_0.append(precision_0)\n",
    "        recalls_1.append(recall_1)\n",
    "        precisions_1.append(precision_1)\n",
    "    \n",
    "        fold_no+=1\n",
    "    \n",
    "    score = sum(scores)/len(scores)\n",
    "    recall_0 = sum(recalls_0)/len(recalls_0)\n",
    "    precision_0 = sum(precisions_0)/len(precisions_0)\n",
    "    recall_1 = sum(recalls_1)/len(recalls_1)\n",
    "    precision_1 = sum(precisions_1)/len(precisions_1)\n",
    "\n",
    "    return score, recall_0, precision_0, recall_1, precision_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "population = create_new_population()\n",
    "print(\"Initial population:\")\n",
    "printChromos(population, True)\n",
    "num_parents_mating = 5\n",
    "num_generations = 10\n",
    "# number of genes for each chromosome\n",
    "num_genes = 6\n",
    "# number of chromosomes for each population\n",
    "num_chromosomes = 10 \n",
    "\n",
    "pop_size=(num_chromosomes,num_genes)\n",
    "\n",
    "# fitness values for each chromosome for the current generation\n",
    "fitness_values = []\n",
    "# fitness vaalues for each chromosome of the last generation\n",
    "last_fitness_values = []\n",
    "\n",
    "gen = 0\n",
    "cromo = 0\n",
    "\n",
    "parents=[]\n",
    "# Parents fitness so we do not repeat calculations on parents\n",
    "parents_fitness = []\n",
    "\n",
    "performances=[]\n",
    "hiperparameters=[]\n",
    "\n",
    "\n",
    "for generation in range(num_generations):\n",
    "    gen+=1\n",
    "    cromo = 0\n",
    "    best_perf_per_gen = -1\n",
    "    \n",
    "    for chromosome in population:\n",
    "        known=False\n",
    "        cromo+=1\n",
    "        score=-1\n",
    "        parentNumber=0\n",
    "        \n",
    "        # If it's a known chromosome we dont need to train the ANN again\n",
    "        # Skips the first generation because we didnt select the parents yet\n",
    "        for savedCromo in parents:\n",
    "            parentNumber+=1\n",
    "            if (np.array_equal(chromosome,savedCromo)):\n",
    "                score = parents_fitness[parentNumber-1]\n",
    "                known = True\n",
    "        \n",
    "        # If it's a new chromosome we need to train the ANN in order to get the accuracy\n",
    "        if (score < 0):\n",
    "            accuracy, recall_0, precision_0, recall_1, precision_1 = evaluateChromosome(chromosome)\n",
    "            score = 0.5 * accuracy + 0.175 * recall_1 + 0.15 * precision_0 + 0.1 * recall_0 + 0.075 * precision_1\n",
    "            \n",
    "        if(not known):\n",
    "            print(\"Generation-{}\".format(gen),\"Chromosome-{}:\".format(cromo))\n",
    "            printChromo(chromosome, True)\n",
    "            print(\"\\tScore {:.2f}\".format(score),\" || Acc: {:.2f}\".format(accuracy),\"|R0: {:.2f} \".format(recall_0),\"|P0: {:.2f} \".format(precision_0), \"|R1: {:.2f} \".format(recall_1),\"|P1: {:.2f} \".format(precision_1))\n",
    "        else:\n",
    "            print(\"Generation-{}\".format(gen),\"Chromosome-{}\".format(cromo),\"scored {:.2f}\".format(score), \" (Chromosome already knowned)\")\n",
    "\n",
    "        \n",
    "        # Keep the scores in fitness_values\n",
    "        fitness_values.append(score)\n",
    "        \n",
    "        # Getting the best hyperparameters per generation to check the evolution at the end\n",
    "        if(best_perf_per_gen < score):\n",
    "            best_perf_per_gen = score\n",
    "            best_cromo_per_gen = chromosome\n",
    "                   \n",
    "    performances.append(best_perf_per_gen)\n",
    "    hiperparameters.append(best_cromo_per_gen)\n",
    "   \n",
    "    #print(performances,\"Best accuracies of each generation\")\n",
    "    #print(hiperparameters,\"Best of each generation\")\n",
    "    \n",
    "    # We store last generation in other array because fitness_values is changed by the select_mating_pool\n",
    "    if(gen == num_generations):\n",
    "        for i in fitness_values:\n",
    "            last_fitness_values.append(i)\n",
    "        print(last_fitness_values,\"Last Fitness Values\")\n",
    "    \n",
    "    parents,parents_fitness = select_mating_pool(population,fitness_values,parents_fitness,num_parents_mating)\n",
    "\n",
    "    # Generating next generation using crossover.\n",
    "    offspring_crossover = crossover(parents,\n",
    "                                        offspring_size=(pop_size[0]-parents.shape[0], num_genes))\n",
    "\n",
    "    # Adding some variations to the offspring using mutation.\n",
    "    offspring_mutation = mutation(offspring_crossover)\n",
    "\n",
    "    # Creating the new population based on the parents and offspring.\n",
    "    population[0:parents.shape[0], :] = parents\n",
    "    population[parents.shape[0]:, :] = offspring_mutation\n",
    "    \n",
    "    # Reset fitness_values\n",
    "    fitness_values=[]\n",
    "\n",
    "end_time = time.time()\n",
    "# Getting the best solution\n",
    "best_solution = population[last_fitness_values.index(np.max(last_fitness_values))]\n",
    "print(\"The best hyperparameters obtained are:\")\n",
    "printChromo(best_solution, True)\n",
    "print(\"with a score of\",np.max(last_fitness_values))\n",
    "print(\"--- GA Computacional time: %s minutes ---\" % ((time.time() - start_time)*60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations=[1,2,3,4,5,6,7,8,9,10]\n",
    "plt.plot(generations,performances,color='g')\n",
    "plt.xlabel('Generations')\n",
    "plt.xticks([1,2,3,4,5,6,7,8,9,10])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy improvement through generations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisys of parameters select by GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = update_model_parameters(chromosome)\n",
    "\n",
    "    \n",
    "history = model.fit(X_test, y_test, validation_split=0.33, epochs=50, batch_size=64, verbose=0)\n",
    "\n",
    "\n",
    "# Visualize history\n",
    "# Plot history: Loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Validation loss history')\n",
    "plt.ylabel('Loss value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot history: Accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Validation accuracy history')\n",
    "plt.ylabel('Accuracy value (%)')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=64, verbose=0)      \n",
    "accuracy, recall_0, precision_0, recall_1, precision_1 = evaluatePredictions(model, X_test, y_test)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "y_pred = roundPredictions(predicted)\n",
    "\n",
    "        \n",
    "target_names = ['Benign', 'Malignant']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(\"True Positives: \" +str(tp))\n",
    "print(\"True Negatives: \" +str(tn))\n",
    "print(\"False Positives: \" +str(fp))\n",
    "print(\"False Negatives: \" +str(fn))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitb31b30c0a70f4385ab74a2040328961f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
